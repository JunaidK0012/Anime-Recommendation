{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f57d76f",
   "metadata": {},
   "source": [
    "# Hybrid Anime Recommendation System\n",
    "\n",
    "This notebook implements a hybrid recommendation engine (content + collaborative filtering) for anime.  \n",
    "We also integrate **MLflow** to track experiments, metrics, and models for better reproducibility and MLOps practices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "760392b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\JunaidKhan\\Desktop\\Anime-Recommendation\\venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70ce0395",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0101a841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 12/12 [00:17<00:00,  1.46s/it] \n"
     ]
    }
   ],
   "source": [
    "model_name = \"hybrid_anime_recommendation\"\n",
    "model_version_alias = \"champion\"\n",
    "\n",
    "# Get the model version using a model URI\n",
    "model_uri = f\"models:/{model_name}@{model_version_alias}\"\n",
    "model = mlflow.pyfunc.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9bdb25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JunaidKhan\\Desktop\\Anime-Recommendation\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 12/12 [00:19<00:00,  1.64s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\JunaidKhan\\Desktop\\Anime-Recommendation\\venv\\lib\\site-packages\\keras\\src\\saving\\legacy\\saved_model\\load.py:107: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\JunaidKhan\\Desktop\\Anime-Recommendation\\venv\\lib\\site-packages\\keras\\src\\engine\\functional.py:156: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "model_name = \"hybrid_anime_recommendation\"\n",
    "model_version = 3\n",
    "\n",
    "model = mlflow.pyfunc.load_model(\n",
    "    model_uri=f\"models:/{model_name}/{model_version}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9136e5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: mlflow-artifacts:/994902288046821146/models/m-4b00d2b1eaa044258f78872ee0b4426f/artifacts\n",
       "  flavor: mlflow.tensorflow\n",
       "  run_id: a2ad3c4395774a699e7f97044c63eccf"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86662051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or connect to SQLite DB\n",
    "conn = sqlite3.connect(\"../data/anime_recommendation.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62f30dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/24 23:32:12 INFO mlflow.tracking.fluent: Experiment with name 'anime_recommendation' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import sqlite3\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")  # logs stored in local file\n",
    "mlflow.set_experiment(\"anime_recommendation\")\n",
    "\n",
    "# Create or connect to SQLite DB\n",
    "conn = sqlite3.connect(\"../data/anime_recommendation.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "affd59e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Pandas display options for better readability\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413ca719",
   "metadata": {},
   "source": [
    "Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e55d7169",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/jikan_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b44e420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = pd.read_csv(\"../data/userratings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a02373",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7dc01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mal_id</th>\n",
       "      <th>url</th>\n",
       "      <th>images</th>\n",
       "      <th>trailer</th>\n",
       "      <th>approved</th>\n",
       "      <th>titles</th>\n",
       "      <th>title</th>\n",
       "      <th>title_english</th>\n",
       "      <th>title_japanese</th>\n",
       "      <th>title_synonyms</th>\n",
       "      <th>type</th>\n",
       "      <th>source</th>\n",
       "      <th>episodes</th>\n",
       "      <th>status</th>\n",
       "      <th>airing</th>\n",
       "      <th>aired</th>\n",
       "      <th>duration</th>\n",
       "      <th>rating</th>\n",
       "      <th>score</th>\n",
       "      <th>scored_by</th>\n",
       "      <th>rank</th>\n",
       "      <th>popularity</th>\n",
       "      <th>members</th>\n",
       "      <th>favorites</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>background</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>broadcast</th>\n",
       "      <th>producers</th>\n",
       "      <th>licensors</th>\n",
       "      <th>studios</th>\n",
       "      <th>genres</th>\n",
       "      <th>explicit_genres</th>\n",
       "      <th>themes</th>\n",
       "      <th>demographics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://myanimelist.net/anime/1/Cowboy_Bebop</td>\n",
       "      <td>{'jpg': {'image_url': 'https://cdn.myanimelist...</td>\n",
       "      <td>{'youtube_id': 'gY5nDXOtv_o', 'url': 'https://...</td>\n",
       "      <td>True</td>\n",
       "      <td>[{'type': 'Default', 'title': 'Cowboy Bebop'},...</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>Cowboy Bebop</td>\n",
       "      <td>カウボーイビバップ</td>\n",
       "      <td>[]</td>\n",
       "      <td>TV</td>\n",
       "      <td>Original</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>False</td>\n",
       "      <td>{'from': '1998-04-03T00:00:00+00:00', 'to': '1...</td>\n",
       "      <td>24 min per ep</td>\n",
       "      <td>R - 17+ (violence &amp; profanity)</td>\n",
       "      <td>8.75</td>\n",
       "      <td>965324.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>43</td>\n",
       "      <td>1866337</td>\n",
       "      <td>82455</td>\n",
       "      <td>Crime is timeless. By the year 2071, humanity ...</td>\n",
       "      <td>When Cowboy Bebop first aired in spring of 199...</td>\n",
       "      <td>spring</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>{'day': 'Saturdays', 'time': '01:00', 'timezon...</td>\n",
       "      <td>[{'mal_id': 23, 'type': 'anime', 'name': 'Band...</td>\n",
       "      <td>[{'mal_id': 102, 'type': 'anime', 'name': 'Fun...</td>\n",
       "      <td>[{'mal_id': 14, 'type': 'anime', 'name': 'Sunr...</td>\n",
       "      <td>[{'mal_id': 1, 'type': 'anime', 'name': 'Actio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'mal_id': 50, 'type': 'anime', 'name': 'Adul...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>https://myanimelist.net/anime/5/Cowboy_Bebop__...</td>\n",
       "      <td>{'jpg': {'image_url': 'https://cdn.myanimelist...</td>\n",
       "      <td>{'youtube_id': None, 'url': None, 'embed_url':...</td>\n",
       "      <td>True</td>\n",
       "      <td>[{'type': 'Default', 'title': 'Cowboy Bebop: T...</td>\n",
       "      <td>Cowboy Bebop: Tengoku no Tobira</td>\n",
       "      <td>Cowboy Bebop: The Movie</td>\n",
       "      <td>カウボーイビバップ 天国の扉</td>\n",
       "      <td>[\"Cowboy Bebop: Knockin' on Heaven's Door\"]</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Original</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>False</td>\n",
       "      <td>{'from': '2001-09-01T00:00:00+00:00', 'to': No...</td>\n",
       "      <td>1 hr 55 min</td>\n",
       "      <td>R - 17+ (violence &amp; profanity)</td>\n",
       "      <td>8.38</td>\n",
       "      <td>215590.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>619</td>\n",
       "      <td>378478</td>\n",
       "      <td>1582</td>\n",
       "      <td>Another day, another bounty—such is the life o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'day': None, 'time': None, 'timezone': None, ...</td>\n",
       "      <td>[{'mal_id': 14, 'type': 'anime', 'name': 'Sunr...</td>\n",
       "      <td>[{'mal_id': 15, 'type': 'anime', 'name': 'Sony...</td>\n",
       "      <td>[{'mal_id': 4, 'type': 'anime', 'name': 'Bones...</td>\n",
       "      <td>[{'mal_id': 1, 'type': 'anime', 'name': 'Actio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'mal_id': 50, 'type': 'anime', 'name': 'Adul...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>https://myanimelist.net/anime/6/Trigun</td>\n",
       "      <td>{'jpg': {'image_url': 'https://cdn.myanimelist...</td>\n",
       "      <td>{'youtube_id': 'bJVyIXeUznY', 'url': 'https://...</td>\n",
       "      <td>True</td>\n",
       "      <td>[{'type': 'Default', 'title': 'Trigun'}, {'typ...</td>\n",
       "      <td>Trigun</td>\n",
       "      <td>Trigun</td>\n",
       "      <td>トライガン</td>\n",
       "      <td>[]</td>\n",
       "      <td>TV</td>\n",
       "      <td>Manga</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Finished Airing</td>\n",
       "      <td>False</td>\n",
       "      <td>{'from': '1998-04-01T00:00:00+00:00', 'to': '1...</td>\n",
       "      <td>24 min per ep</td>\n",
       "      <td>PG-13 - Teens 13 or older</td>\n",
       "      <td>8.22</td>\n",
       "      <td>373517.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>252</td>\n",
       "      <td>763911</td>\n",
       "      <td>16027</td>\n",
       "      <td>Vash the Stampede is the man with a $$60,000,0...</td>\n",
       "      <td>The Japanese release by Victor Entertainment h...</td>\n",
       "      <td>spring</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>{'day': 'Thursdays', 'time': '01:15', 'timezon...</td>\n",
       "      <td>[{'mal_id': 123, 'type': 'anime', 'name': 'Vic...</td>\n",
       "      <td>[{'mal_id': 102, 'type': 'anime', 'name': 'Fun...</td>\n",
       "      <td>[{'mal_id': 11, 'type': 'anime', 'name': 'Madh...</td>\n",
       "      <td>[{'mal_id': 1, 'type': 'anime', 'name': 'Actio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'mal_id': 50, 'type': 'anime', 'name': 'Adul...</td>\n",
       "      <td>[{'mal_id': 27, 'type': 'anime', 'name': 'Shou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mal_id                                                url  \\\n",
       "0       1       https://myanimelist.net/anime/1/Cowboy_Bebop   \n",
       "1       5  https://myanimelist.net/anime/5/Cowboy_Bebop__...   \n",
       "2       6             https://myanimelist.net/anime/6/Trigun   \n",
       "\n",
       "                                              images  \\\n",
       "0  {'jpg': {'image_url': 'https://cdn.myanimelist...   \n",
       "1  {'jpg': {'image_url': 'https://cdn.myanimelist...   \n",
       "2  {'jpg': {'image_url': 'https://cdn.myanimelist...   \n",
       "\n",
       "                                             trailer  approved  \\\n",
       "0  {'youtube_id': 'gY5nDXOtv_o', 'url': 'https://...      True   \n",
       "1  {'youtube_id': None, 'url': None, 'embed_url':...      True   \n",
       "2  {'youtube_id': 'bJVyIXeUznY', 'url': 'https://...      True   \n",
       "\n",
       "                                              titles  \\\n",
       "0  [{'type': 'Default', 'title': 'Cowboy Bebop'},...   \n",
       "1  [{'type': 'Default', 'title': 'Cowboy Bebop: T...   \n",
       "2  [{'type': 'Default', 'title': 'Trigun'}, {'typ...   \n",
       "\n",
       "                             title            title_english  title_japanese  \\\n",
       "0                     Cowboy Bebop             Cowboy Bebop       カウボーイビバップ   \n",
       "1  Cowboy Bebop: Tengoku no Tobira  Cowboy Bebop: The Movie  カウボーイビバップ 天国の扉   \n",
       "2                           Trigun                   Trigun           トライガン   \n",
       "\n",
       "                                title_synonyms   type    source  episodes  \\\n",
       "0                                           []     TV  Original      26.0   \n",
       "1  [\"Cowboy Bebop: Knockin' on Heaven's Door\"]  Movie  Original       1.0   \n",
       "2                                           []     TV     Manga      26.0   \n",
       "\n",
       "            status  airing                                              aired  \\\n",
       "0  Finished Airing   False  {'from': '1998-04-03T00:00:00+00:00', 'to': '1...   \n",
       "1  Finished Airing   False  {'from': '2001-09-01T00:00:00+00:00', 'to': No...   \n",
       "2  Finished Airing   False  {'from': '1998-04-01T00:00:00+00:00', 'to': '1...   \n",
       "\n",
       "        duration                          rating  score  scored_by   rank  \\\n",
       "0  24 min per ep  R - 17+ (violence & profanity)   8.75   965324.0   46.0   \n",
       "1    1 hr 55 min  R - 17+ (violence & profanity)   8.38   215590.0  194.0   \n",
       "2  24 min per ep       PG-13 - Teens 13 or older   8.22   373517.0  342.0   \n",
       "\n",
       "   popularity  members  favorites  \\\n",
       "0          43  1866337      82455   \n",
       "1         619   378478       1582   \n",
       "2         252   763911      16027   \n",
       "\n",
       "                                            synopsis  \\\n",
       "0  Crime is timeless. By the year 2071, humanity ...   \n",
       "1  Another day, another bounty—such is the life o...   \n",
       "2  Vash the Stampede is the man with a $$60,000,0...   \n",
       "\n",
       "                                          background  season    year  \\\n",
       "0  When Cowboy Bebop first aired in spring of 199...  spring  1998.0   \n",
       "1                                                NaN     NaN     NaN   \n",
       "2  The Japanese release by Victor Entertainment h...  spring  1998.0   \n",
       "\n",
       "                                           broadcast  \\\n",
       "0  {'day': 'Saturdays', 'time': '01:00', 'timezon...   \n",
       "1  {'day': None, 'time': None, 'timezone': None, ...   \n",
       "2  {'day': 'Thursdays', 'time': '01:15', 'timezon...   \n",
       "\n",
       "                                           producers  \\\n",
       "0  [{'mal_id': 23, 'type': 'anime', 'name': 'Band...   \n",
       "1  [{'mal_id': 14, 'type': 'anime', 'name': 'Sunr...   \n",
       "2  [{'mal_id': 123, 'type': 'anime', 'name': 'Vic...   \n",
       "\n",
       "                                           licensors  \\\n",
       "0  [{'mal_id': 102, 'type': 'anime', 'name': 'Fun...   \n",
       "1  [{'mal_id': 15, 'type': 'anime', 'name': 'Sony...   \n",
       "2  [{'mal_id': 102, 'type': 'anime', 'name': 'Fun...   \n",
       "\n",
       "                                             studios  \\\n",
       "0  [{'mal_id': 14, 'type': 'anime', 'name': 'Sunr...   \n",
       "1  [{'mal_id': 4, 'type': 'anime', 'name': 'Bones...   \n",
       "2  [{'mal_id': 11, 'type': 'anime', 'name': 'Madh...   \n",
       "\n",
       "                                              genres explicit_genres  \\\n",
       "0  [{'mal_id': 1, 'type': 'anime', 'name': 'Actio...              []   \n",
       "1  [{'mal_id': 1, 'type': 'anime', 'name': 'Actio...              []   \n",
       "2  [{'mal_id': 1, 'type': 'anime', 'name': 'Actio...              []   \n",
       "\n",
       "                                              themes  \\\n",
       "0  [{'mal_id': 50, 'type': 'anime', 'name': 'Adul...   \n",
       "1  [{'mal_id': 50, 'type': 'anime', 'name': 'Adul...   \n",
       "2  [{'mal_id': 50, 'type': 'anime', 'name': 'Adul...   \n",
       "\n",
       "                                        demographics  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2  [{'mal_id': 27, 'type': 'anime', 'name': 'Shou...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f304f098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anime dataset shape: (26720, 36)\n"
     ]
    }
   ],
   "source": [
    "# Shape of the anime dataset\n",
    "print(\"Anime dataset shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1cb6966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in anime dataset:\n",
      " mal_id             26564\n",
      "url                26564\n",
      "images             26364\n",
      "trailer             4920\n",
      "approved               1\n",
      "titles             26564\n",
      "title              26563\n",
      "title_english      10998\n",
      "title_japanese     25462\n",
      "title_synonyms     12463\n",
      "type                   9\n",
      "source                17\n",
      "episodes             250\n",
      "status                 3\n",
      "airing                 2\n",
      "aired              16116\n",
      "duration             333\n",
      "rating                 6\n",
      "score                559\n",
      "scored_by           8712\n",
      "rank               16055\n",
      "popularity         20364\n",
      "members            11508\n",
      "favorites           1901\n",
      "synopsis           21510\n",
      "background          2556\n",
      "season                 4\n",
      "year                  65\n",
      "broadcast            623\n",
      "producers           4701\n",
      "licensors            265\n",
      "studios             1681\n",
      "genres               962\n",
      "explicit_genres        1\n",
      "themes               948\n",
      "demographics           8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of unique values per column in anime dataset\n",
    "print(\"\\nUnique values in anime dataset:\\n\", df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f8036d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Username</th>\n",
       "      <th>Anime ID</th>\n",
       "      <th>Anime Title</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104748</td>\n",
       "      <td>JHaytko</td>\n",
       "      <td>889</td>\n",
       "      <td>Black Lagoon</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104748</td>\n",
       "      <td>JHaytko</td>\n",
       "      <td>27</td>\n",
       "      <td>Trinity Blood</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104750</td>\n",
       "      <td>A-n-i-m-e</td>\n",
       "      <td>50</td>\n",
       "      <td>Aa! Megami-sama! (TV)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User ID   Username  Anime ID            Anime Title  Score\n",
       "0   104748    JHaytko       889           Black Lagoon      9\n",
       "1   104748    JHaytko        27          Trinity Blood      7\n",
       "2   104750  A-n-i-m-e        50  Aa! Megami-sama! (TV)     10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b0d296a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User dataset shape: (5279841, 5)\n"
     ]
    }
   ],
   "source": [
    "# Shape of the user ratings dataset\n",
    "print(\"\\nUser dataset shape:\", user.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de865c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values in user dataset:\n",
      " User ID        52375\n",
      "Username       52373\n",
      "Anime ID       14464\n",
      "Anime Title    14510\n",
      "Score             10\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of unique values per column in user ratings dataset\n",
    "print(\"\\nUnique values in user dataset:\\n\", user.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea26926",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16a50c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows from anime dataset\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdd29a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows in user dataset\n",
    "user.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "743edc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many ratings each Anime ID has received\n",
    "counts1 = user['Anime ID'].value_counts()\n",
    "\n",
    "# Keep only those users/anime pairs where the Anime has at least 5 ratings\n",
    "filtered_user = user[user[\"Anime ID\"].isin(counts1[counts1>=5].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d747bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These shows won't be useful for recommendations\n",
    "not_yet_aired = df[df.status == \"Not yet aired\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34d9edfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only anime that exist in the filtered user dataset\n",
    "df1 = df[df['mal_id'].isin(filtered_user['Anime ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18767614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mal_id                0\n",
       "url                   0\n",
       "images                0\n",
       "trailer               0\n",
       "approved              0\n",
       "titles                0\n",
       "title                 0\n",
       "title_english      4161\n",
       "title_japanese       12\n",
       "title_synonyms        0\n",
       "type                  0\n",
       "source                0\n",
       "episodes             29\n",
       "status                0\n",
       "airing                0\n",
       "aired                 0\n",
       "duration              0\n",
       "rating               15\n",
       "score                 7\n",
       "scored_by             7\n",
       "rank               1572\n",
       "popularity            0\n",
       "members               0\n",
       "favorites             0\n",
       "synopsis             83\n",
       "background         9020\n",
       "season             6753\n",
       "year               6753\n",
       "broadcast             0\n",
       "producers             0\n",
       "licensors             0\n",
       "studios               0\n",
       "genres                0\n",
       "explicit_genres       0\n",
       "themes                0\n",
       "demographics          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing values check\n",
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c8af94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JunaidKhan\\AppData\\Local\\Temp\\ipykernel_23220\\2726921812.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.dropna(subset=['synopsis','rating'],inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df1.dropna(subset=['synopsis','rating'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162cf459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JunaidKhan\\AppData\\Local\\Temp\\ipykernel_23220\\229172688.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.producers = df1.producers.apply(ast.literal_eval)\n",
      "C:\\Users\\JunaidKhan\\AppData\\Local\\Temp\\ipykernel_23220\\229172688.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.images = df1.images.apply(ast.literal_eval)\n",
      "C:\\Users\\JunaidKhan\\AppData\\Local\\Temp\\ipykernel_23220\\229172688.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.trailer = df1.trailer.apply(ast.literal_eval)\n",
      "C:\\Users\\JunaidKhan\\AppData\\Local\\Temp\\ipykernel_23220\\229172688.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.titles = df1.titles.apply(ast.literal_eval)\n",
      "C:\\Users\\JunaidKhan\\AppData\\Local\\Temp\\ipykernel_23220\\229172688.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.aired = df1.aired.apply(ast.literal_eval)\n",
      "C:\\Users\\JunaidKhan\\AppData\\Local\\Temp\\ipykernel_23220\\229172688.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.broadcast = df1.broadcast.apply(ast.literal_eval)\n",
      "C:\\Users\\JunaidKhan\\AppData\\Local\\Temp\\ipykernel_23220\\229172688.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.licensors = df1.licensors.apply(ast.literal_eval)\n",
      "C:\\Users\\JunaidKhan\\AppData\\Local\\Temp\\ipykernel_23220\\229172688.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.studios = df1.studios.apply(ast.literal_eval)\n",
      "C:\\Users\\JunaidKhan\\AppData\\Local\\Temp\\ipykernel_23220\\229172688.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.genres = df1.genres.apply(ast.literal_eval)\n",
      "C:\\Users\\JunaidKhan\\AppData\\Local\\Temp\\ipykernel_23220\\229172688.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.themes = df1.themes.apply(ast.literal_eval)\n",
      "C:\\Users\\JunaidKhan\\AppData\\Local\\Temp\\ipykernel_23220\\229172688.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.demographics = df1.demographics.apply(ast.literal_eval)\n"
     ]
    }
   ],
   "source": [
    "import ast \n",
    "\n",
    "# Many columns are stored as stringified dictionaries/lists (from JSON).\n",
    "# We parse them into proper Python objects.\n",
    "\n",
    "df1.producers = df1.producers.apply(ast.literal_eval)\n",
    "df1.images = df1.images.apply(ast.literal_eval)\n",
    "df1.trailer = df1.trailer.apply(ast.literal_eval)\n",
    "df1.titles = df1.titles.apply(ast.literal_eval)\n",
    "df1.aired = df1.aired.apply(ast.literal_eval)\n",
    "df1.broadcast = df1.broadcast.apply(ast.literal_eval)\n",
    "df1.licensors = df1.licensors.apply(ast.literal_eval)\n",
    "df1.studios = df1.studios.apply(ast.literal_eval)\n",
    "df1.genres = df1.genres.apply(ast.literal_eval)\n",
    "df1.themes = df1.themes.apply(ast.literal_eval)\n",
    "df1.demographics = df1.demographics.apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403c37f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JunaidKhan\\AppData\\Local\\Temp\\ipykernel_23220\\2778330362.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[['producers','licensors','studios','genres','themes','demographics','trailer','aired','image']] = df1.apply(extract_info, axis=1)\n",
      "C:\\Users\\JunaidKhan\\AppData\\Local\\Temp\\ipykernel_23220\\2778330362.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1[['producers','licensors','studios','genres','themes','demographics','trailer','aired','image']] = df1.apply(extract_info, axis=1)\n"
     ]
    }
   ],
   "source": [
    "def extract_info(row):\n",
    "    \"\"\"\n",
    "    Extracts nested metadata (producers, genres, images, etc.) \n",
    "    from the anime dataset row.\n",
    "    \"\"\"\n",
    "    producer_names = [producer['name'] for producer in row['producers']]\n",
    "    licensors_names = [licensor['name'] for licensor in row['licensors']]\n",
    "    studios_names = [studio['name'] for studio in row['studios']]\n",
    "    genres = [genre['name'] for genre in row['genres']]\n",
    "    themes = [theme['name'] for theme in row['themes']]\n",
    "    demographics = [dg['name'] for dg in row['demographics']]\n",
    "    \n",
    "    # Trailer URL (if available)\n",
    "    embed_url = row['trailer']['embed_url'] if row['trailer'] else None\n",
    "    # Aired date (string format)\n",
    "    aired = row['aired']['string'] if row['aired'] else None\n",
    "    # Image URL (large cover image)\n",
    "    large_image_url = row['images']['jpg']['large_image_url'] if row['images'] else None\n",
    "    \n",
    "    return pd.Series([producer_names, licensors_names,studios_names,genres,themes,demographics,embed_url,aired, large_image_url])\n",
    "\n",
    "# Apply the function to each row of the DataFrame\n",
    "df1[['producers','licensors','studios','genres','themes','demographics','trailer','aired','image']] = df1.apply(extract_info, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b784fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop anime with no genre information\n",
    "df1 = df1[~df1['genres'].apply(lambda x: x == [])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "083ad4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b36ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Pattern to remove annotations like [Written by MAL Rewrite] or (Source info)\n",
    "pattern = r\"\\[Written by MAL Rewrite\\]|\\(.*Source:.*\\)\" \n",
    "\n",
    "# Removing the pattern using regular expressions\n",
    "df1['synopsis'] = df1['synopsis'].str.replace(pattern, '', regex=True).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5419638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newline_numbers(text):\n",
    "    \"\"\"\n",
    "    Cleans anime synopsis text by:\n",
    "    - Removing newlines\n",
    "    - Removing digits\n",
    "    - Removing punctuation\n",
    "    - Lowercasing\n",
    "    \"\"\"\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fae0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text cleaning\n",
    "df1['synopsis_cleaned'] = df1.synopsis.apply(remove_newline_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52777973",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# Lemmatize and remove stop words\n",
    "df1['synopsis_cleaned'] = df1['synopsis_cleaned'].apply(lambda x: \" \".join([token.lemma_ for token in nlp(x) if not token.is_stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a428bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map verbose rating strings into simpler categories\n",
    "rating_map = {\n",
    "    \"PG-13 - Teens 13 or older\": \"PG-13\",\n",
    "    \"R - 17+ (violence & profanity)\": \"R17\",\n",
    "    \"Rx - Hentai\": \"Rx\",\n",
    "    \"R+ - Mild Nudity\": \"R+\",\n",
    "    \"G - All Ages\": \"G\",\n",
    "    \"PG - Children\": \"PG\"\n",
    "}\n",
    "\n",
    "# Use the map to replace the values in the 'rating' column\n",
    "df1['rating'] = df1['rating'].replace(rating_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce19f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace empty lists with placeholder values\n",
    "df1['themes'] = df1['themes'].apply(lambda x:[\"unknown_theme\"] if x == [] else x )\n",
    "df1['demographics'] = df1['demographics'].apply(lambda x:[\"unknown_demographics\"] if x == [] else x )\n",
    "\n",
    "# Fill missing season values\n",
    "df1['season'] = df1['season'].fillna(\"unknownseason\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef926db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season(x):\n",
    "    \"\"\"\n",
    "    Derive season (spring/summer/fall/winter) from the month in the aired date.\n",
    "    \"\"\"\n",
    "    spring = [\"Mar\",\"Apr\",\"May\"]\n",
    "    summer = [\"Jun\",\"Jul\",\"Aug\"]\n",
    "    fall = [\"Sep\",\"Oct\",\"Nov\"]\n",
    "    winter = [\"Dec\",\"Jan\",\"Feb\"]\n",
    "    y = x[:3]  # Extract first 3 letters (month abbreviation)\n",
    "    if y in spring:\n",
    "        return \"spring\"\n",
    "    elif y in winter:\n",
    "        return \"winter\"\n",
    "    elif y in fall:\n",
    "        return \"fall\"\n",
    "    elif y in summer:\n",
    "        return \"summer\"\n",
    "\n",
    "df1.season = df1.aired.apply(get_season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3af658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split aired string and extract year part\n",
    "df1.year = df1.aired.str.split(',').str[1].str[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b0e8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na(row):\n",
    "    \"\"\"\n",
    "    Fills missing 'year' values based on aired string format.\n",
    "    \"\"\"\n",
    "    if pd.isna(row['year']):\n",
    "        if len(row['aired']) == 4:\n",
    "            return row['aired']\n",
    "        elif len(row['aired']) == 12:\n",
    "            return row['aired'][:4]\n",
    "        else:\n",
    "            return row['aired'][4:8]\n",
    "    else:\n",
    "        return row['year']\n",
    "\n",
    "df1['year'] = df1.apply(fill_na, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b631879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns for recommendation system\n",
    "data = df1[['mal_id', 'url', 'trailer', 'title',\n",
    "       'title_english', 'type', 'source',\n",
    "       'episodes', 'status', 'aired', 'duration', 'rating', 'score',\n",
    "       'scored_by', 'rank', 'popularity', 'members', 'favorites', 'synopsis','synopsis_cleaned',\n",
    "       'background', 'season', 'year', 'producers', 'licensors',\n",
    "       'studios', 'genres', 'themes', 'demographics',\n",
    "       'image']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe52805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list-like fields into comma-separated strings for easier processing\n",
    "for col in [\"producers\", \"licensors\", \"genres\", \"studios\", \"themes\", \"demographics\"]:\n",
    "    data[col] = data[col].apply(lambda x: \",\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3212569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NSFW or less relevant genres\n",
    "data = data[~(data.genres.str.contains(\"Hentai\")|data.genres.str.contains(\"Erotica\")|data.genres.str.contains(\"Boys Love\")|data.genres.str.contains(\"Girls Love\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc5fc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Action': 3339, 'Award Winning': 200, 'Sci-Fi': 2088, 'Adventure': 2086, 'Drama': 1757, 'Mystery': 681, 'Supernatural': 930, 'Fantasy': 2542, 'Sports': 411, 'Comedy': 3645, 'Romance': 1527, 'Slice of Life': 683, 'Suspense': 281, 'Ecchi': 709, 'Gourmet': 85, 'Avant Garde': 155, 'Horror': 335}\n"
     ]
    }
   ],
   "source": [
    "# Count how many times each genre appears\n",
    "genre_counts = {}\n",
    "for row in data['genres']:\n",
    "    for genre in row.split(','):\n",
    "        if genre in genre_counts:\n",
    "            genre_counts[genre] += 1\n",
    "        else:\n",
    "            genre_counts[genre] = 1\n",
    "\n",
    "print(\"Genre frequency counts:\\n\", genre_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d480c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop entries where favorites = 0 (less popular)\n",
    "data = data[data.favorites != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8841aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index after filtering\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b82a4",
   "metadata": {},
   "source": [
    "CONTENT BASED FILTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04857148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical columns\n",
    "genres_df = data.genres.str.get_dummies(sep=',')\n",
    "studios_df = data.studios.str.get_dummies(sep=',')\n",
    "themes_df = data.themes.str.get_dummies(sep=',')\n",
    "demographics_df = data.demographics.str.get_dummies(sep=',')\n",
    "status_df = data.status.str.get_dummies()\n",
    "season_df = data.season.str.get_dummies()\n",
    "type_df = data.type.str.get_dummies()\n",
    "source_df = data.source.str.get_dummies()\n",
    "rating_df = data.rating.str.get_dummies()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86133ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure year is integer\n",
    "data.year = data.year.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1ba9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF on cleaned synopsis\n",
    "vectorizer = TfidfVectorizer() \n",
    "overview_matrix = vectorizer.fit_transform(data['synopsis_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd1a65bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8606, 30640)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d88e0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sparse matrix to dense DataFrame\n",
    "overview_matrix = overview_matrix.toarray()\n",
    "overview_df = pd.DataFrame(overview_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c17474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "num_components = 1000\n",
    "\n",
    "# Dimensionality reduction with PCA\n",
    "pca = PCA(n_components=num_components)\n",
    "pca_data = pca.fit_transform(overview_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6dc9065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data = pd.DataFrame(pca_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62e366de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8606, 1000)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd79f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine PCA-transformed synopsis features with categorical encodings\n",
    "combined_features = pd.concat([pca_data,source_df,type_df,genres_df,demographics_df,themes_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d57d3f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8606, 1100)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35413bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8606, 8606)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Compute cosine similarity between all anime entries\n",
    "similarity_matrix = cosine_similarity(combined_features)\n",
    "print(\"Similarity matrix shape:\", similarity_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474492ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(anime: str, top_n: int = 20):\n",
    "    \"\"\"\n",
    "    Recommend similar anime using content-based filtering.\n",
    "\n",
    "    Parameters:\n",
    "    - anime (str): Title or English title of the anime\n",
    "    - top_n (int): Number of recommendations to return (default = 20)\n",
    "    \"\"\"\n",
    "    # Get index of the given anime\n",
    "    index = data[(data['title'] == anime) | (data['title_english'] == anime)].index[0]\n",
    "    \n",
    "    # Sort similarities in descending order (excluding the anime itself)\n",
    "    distances = sorted(list(enumerate(similarity_matrix[index])),reverse=True,key= lambda x:x[1])\n",
    "    \n",
    "    # Print top recommendations\n",
    "    for i in distances[1:top_n]:\n",
    "        \n",
    "        print(data.iloc[i[0]].title,\"---\",i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8779ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kimetsu no Yaiba: Katanakaji no Sato-hen --- 0.9035888230945653\n",
      "Kimetsu no Yaiba: Yuukaku-hen --- 0.899188506470277\n",
      "Kimetsu no Yaiba: Mugen Ressha-hen --- 0.8931762252414965\n",
      "Kimetsu no Yaiba: Hashira Geiko-hen --- 0.88715760396355\n",
      "Nokemono-tachi no Yoru --- 0.8147014887809835\n",
      "Senkaiden Houshin Engi --- 0.8078576510509909\n",
      "Jujutsu Kaisen --- 0.8063498300831085\n",
      "Kuroshitsuji II --- 0.76841715118485\n",
      "Vanitas no Karte Part 2 --- 0.7665458808883701\n",
      "Orient: Awajishima Gekitou-hen --- 0.7644520160907416\n",
      "Orient --- 0.7618520270021595\n",
      "Vanitas no Karte --- 0.7605607336980846\n",
      "Kuroshitsuji: Book of Circus --- 0.7601304177475053\n",
      "Sengoku Youko: Yonaoshi Kyoudai-hen --- 0.7558232072483551\n",
      "Kuroshitsuji --- 0.7527823547322182\n",
      "Kimetsu no Yaiba Movie: Mugen Ressha-hen --- 0.7520176329929539\n",
      "Ragna Crimson --- 0.7372769737117499\n",
      "Chainsaw Man --- 0.734025442552698\n",
      "Yu☆Gi☆Oh! Zexal Second --- 0.7332565149351102\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "recommend(\"Kimetsu no Yaiba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc83107e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8606"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save cleaned anime dataset to SQLite\n",
    "data.to_sql(\"anime\", conn, if_exists=\"replace\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a62a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV for external use\n",
    "data.to_csv(\"../data/cleaned_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90daead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save similarity matrix as pickle\n",
    "import pickle\n",
    "pickle.dump(similarity_matrix,open('../model/similarity_matrix.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f36153a",
   "metadata": {},
   "source": [
    "MATRIX FACTORIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de333352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align user ratings with filtered anime dataset\n",
    "filtered_user = filtered_user[filtered_user['Anime ID'].isin(data.mal_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d46a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only active users (those with >50 ratings)\n",
    "counts = filtered_user['User ID'].value_counts()\n",
    "filtered_user = filtered_user[filtered_user[\"User ID\"].isin(counts[counts>50].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23af527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User ID        24008\n",
       "Username       24007\n",
       "Anime ID        8606\n",
       "Anime Title     8649\n",
       "Score             10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Unique values after filtering:\\n\", filtered_user.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6771a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index and keep only relevant columns\n",
    "filtered_user = filtered_user.reset_index(drop=True)\n",
    "filtered_user = filtered_user.iloc[:, [0,2,3,4]]\n",
    "filtered_user.rename(columns={'User ID':'user_id','Anime ID':'anime_id'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0cb8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode user_id and anime_id to integer codes\n",
    "user_ids = pd.Categorical(filtered_user[\"user_id\"])\n",
    "filtered_user[\"user_id_encoded\"] = user_ids.codes\n",
    "\n",
    "anime_ids = pd.Categorical(filtered_user[\"anime_id\"])\n",
    "filtered_user[\"anime_id_encoded\"] = anime_ids.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f94dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Normalize scores to [0, 1] for better training stability\n",
    "minmax = MinMaxScaler()\n",
    "filtered_user[\"Score_scaled\"] = minmax.fit_transform(filtered_user[[\"Score\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "70d3f15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final filtered dataset shape: (4640149, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"Final filtered dataset shape:\", filtered_user.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dd78f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    filtered_user[[\"user_id_encoded\", \"anime_id_encoded\"]], filtered_user[\"Score_scaled\"], test_size=0.2, random_state=4 , shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "65801034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8606"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_user.anime_id_encoded.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a826513e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8606"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.anime_id_encoded.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "13bdc1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f6d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define embedding sizes\n",
    "num_users = len(set(X_train[\"user_id_encoded\"]))  \n",
    "num_animes = len(set(X_train[\"anime_id_encoded\"]))  \n",
    "embedding_dim = 64  # Latent factor dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9852ed6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\JunaidKhan\\Desktop\\Anime-Recommendation\\venv\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\JunaidKhan\\Desktop\\Anime-Recommendation\\venv\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " user_encoded (InputLayer)   [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " anime_encoded (InputLayer)  [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " user_embedding (Embedding)  (None, 1, 64)                1536512   ['user_encoded[0][0]']        \n",
      "                                                                                                  \n",
      " anime_embedding (Embedding  (None, 1, 64)                550784    ['anime_encoded[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dot_product (Dot)           (None, 1, 1)                 0         ['user_embedding[0][0]',      \n",
      "                                                                     'anime_embedding[0][0]']     \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 1)                    0         ['dot_product[0][0]']         \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 32)                   64        ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    33        ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2087393 (7.96 MB)\n",
      "Trainable params: 2087393 (7.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# User & Anime input layers\n",
    "user_input = keras.layers.Input(name='user_encoded',shape=(1,))\n",
    "anime_input = keras.layers.Input(name='anime_encoded',shape=(1,))\n",
    "\n",
    "# Embedding layers\n",
    "user_embeddings = keras.layers.Embedding(num_users, embedding_dim, name='user_embedding')(user_input)\n",
    "anime_embeddings = keras.layers.Embedding(num_animes, embedding_dim,name='anime_embedding')(anime_input)\n",
    "\n",
    "# Dot product of embeddings\n",
    "dot_product = keras.layers.Dot(name='dot_product',axes=2)([user_embeddings, anime_embeddings])\n",
    "flattened = keras.layers.Flatten()(dot_product)\n",
    "\n",
    "# Dense layers for learning non-linear interactions\n",
    "dense = keras.layers.Dense(32, activation='relu')(flattened)\n",
    "output = keras.layers.Dense(1, activation=\"sigmoid\")(dense)  # Optional bias can be added before this layer\n",
    "\n",
    "# Build and compile model\n",
    "model = keras.Model(\n",
    "    inputs=[user_input, anime_input], outputs=output\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=\"mse\", metrics=[\"mse\", \"mae\"]  # Regression metrics\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dbd567",
   "metadata": {},
   "source": [
    " MODEL TRAINING WITH MLFLOW AUTLOGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b55f1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/24 23:36:33 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
      "2025/09/24 23:36:36 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/09/24 23:36:36 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
      "2025/09/24 23:36:37 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'a2ad3c4395774a699e7f97044c63eccf', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n",
      "2025/09/24 23:36:37 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'list'>. Dataset logging skipped.\n",
      "2025/09/24 23:36:37 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'list' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From c:\\Users\\JunaidKhan\\Desktop\\Anime-Recommendation\\venv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\JunaidKhan\\Desktop\\Anime-Recommendation\\venv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "57994/58002 [============================>.] - ETA: 0s - loss: 0.0221 - mse: 0.0221 - mae: 0.1127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JunaidKhan\\Desktop\\Anime-Recommendation\\venv\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58002/58002 [==============================] - 373s 6ms/step - loss: 0.0221 - mse: 0.0221 - mae: 0.1127 - val_loss: 0.0187 - val_mse: 0.0187 - val_mae: 0.1034\n",
      "Epoch 2/3\n",
      "58002/58002 [==============================] - 386s 7ms/step - loss: 0.0162 - mse: 0.0162 - mae: 0.0950 - val_loss: 0.0180 - val_mse: 0.0180 - val_mae: 0.1012\n",
      "Epoch 3/3\n",
      "58002/58002 [==============================] - 365s 6ms/step - loss: 0.0137 - mse: 0.0137 - mae: 0.0865 - val_loss: 0.0184 - val_mse: 0.0184 - val_mae: 0.1015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/24 23:55:21 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: Cannot log input example or model signature for input with type <class 'list'>. TensorFlow Keras autologging can only log input examples and model signatures for the following input types: numpy.ndarray, dict[string -> numpy.ndarray], tensorflow.keras.utils.Sequence, and tensorflow.data.Dataset (TensorFlow >= 2.1.0 required)\n",
      "2025/09/24 23:55:21 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/09/24 23:55:21 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\JUNAID~1\\AppData\\Local\\Temp\\tmpjks6g0q8\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\JUNAID~1\\AppData\\Local\\Temp\\tmpjks6g0q8\\model\\data\\model\\assets\n",
      "2025/09/24 23:55:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/09/24 23:55:31 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run gregarious-frog-661 at: http://127.0.0.1:8080/#/experiments/994902288046821146/runs/a2ad3c4395774a699e7f97044c63eccf\n",
      "🧪 View experiment at: http://127.0.0.1:8080/#/experiments/994902288046821146\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\JUNAID~1\\AppData\\Local\\Temp\\tmpb65220r9\\model\\data\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\JUNAID~1\\AppData\\Local\\Temp\\tmpb65220r9\\model\\data\\model\\assets\n",
      "2025/09/24 23:55:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Successfully registered model 'hybrid_anime_recommendation'.\n",
      "2025/09/24 23:55:40 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: hybrid_anime_recommendation, version 1\n",
      "Created version '1' of model 'hybrid_anime_recommendation'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x207053dfdf0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.autolog()\n",
    "\n",
    "# model training\n",
    "history = model.fit(\n",
    "    [X_train['user_id_encoded'], X_train['anime_id_encoded']],  # Separate user and anime IDs\n",
    "    y_train,\n",
    "    epochs=3,  # Adjust as needed\n",
    "    batch_size=64,  # Adjust as needed\n",
    "    validation_data=([X_val['user_id_encoded'], X_val['anime_id_encoded']], y_val),\n",
    ")\n",
    "\n",
    "# Log model into MLflow Model Registry\n",
    "mlflow.keras.log_model(\n",
    "    model=model,\n",
    "    name=\"anime_recommender\",\n",
    "    registered_model_name=\"hybrid_anime_recommendation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8bdac791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29001/29001 [==============================] - 28s 964us/step\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "X_test_user = X_val['user_id_encoded']\n",
    "X_test_item = X_val['anime_id_encoded']\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict([X_test_user, X_test_item])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3067a169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in Keras format for reuse\n",
    "model.save('../model/model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1adf7a3",
   "metadata": {},
   "source": [
    "USER-SPECIFIC RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952a836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269/269 [==============================] - 0s 752us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "189                                           Elfen Lied\n",
       "191                                        Jigoku Shoujo\n",
       "664                                    Hellsing Ultimate\n",
       "1324                     Code Geass: Hangyaku no Lelouch\n",
       "2074               Kara no Kyoukai Movie 1: Fukan Fuukei\n",
       "2268                  Code Geass: Hangyaku no Lelouch R2\n",
       "2664    Kara no Kyoukai Movie 2: Satsujin Kousatsu (Zen)\n",
       "2665           Kara no Kyoukai Movie 3: Tsuukaku Zanryuu\n",
       "2817                                Clannad: After Story\n",
       "2848               Kara no Kyoukai Movie 4: Garan no Dou\n",
       "2849                Kara no Kyoukai Movie 5: Mujun Rasen\n",
       "3090     Kara no Kyoukai Movie 7: Satsujin Kousatsu (Go)\n",
       "3146                                       Tsumiki no Ie\n",
       "3914                                         Steins;Gate\n",
       "4326          Steins;Gate Movie: Fuka Ryouiki no Déjà vu\n",
       "4699                                 Gintama': Enchousen\n",
       "6022                                      Kimi no Na wa.\n",
       "6945    Gintama.: Shirogane no Tamashii-hen - Kouhan-sen\n",
       "7790                                    Holo no Graffiti\n",
       "8361                                   Sousou no Frieren\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: get recommendations for a given user\n",
    "\n",
    "user_id = 909      # Example user ID\n",
    "anime_ids = np.array(list(set(filtered_user.anime_id_encoded)))\n",
    "anime_size = anime_ids.shape[0]\n",
    "\n",
    "# Repeat user_id for all anime entries (for batch prediction)\n",
    "user_ids = np.array([user_id]*anime_size)\n",
    "\n",
    "# Predict ratings for all anime for this user\n",
    "predictions = model.predict([user_ids, anime_ids])\n",
    "\n",
    "# Get top 20 recommended anime indices\n",
    "top_anime_index = predictions.flatten().argsort()[-20:][::-1]\n",
    "\n",
    "# Map encoded anime IDs back to actual anime dataset\n",
    "a = filtered_user[filtered_user.anime_id_encoded.isin(top_anime_index)][['anime_id']]\n",
    "rec_anime = a.anime_id.unique()\n",
    "print(\"Top 20 recommendations for user:\", user_id)\n",
    "print(data[data.mal_id.isin(rec_anime)][\"title\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4cc623",
   "metadata": {},
   "source": [
    "ANIME-TO-ANIME SIMILARITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ef47b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10                                                 Naruto\n",
       "231                                                Bleach\n",
       "393     Naruto Movie 1: Dai Katsugeki!! Yuki Hime Shin...\n",
       "531     Naruto: Takigakure no Shitou - Ore ga Eiyuu Da...\n",
       "796     Naruto Movie 2: Dai Gekitotsu! Maboroshi no Ch...\n",
       "1452                                   Naruto: Shippuuden\n",
       "1781    Naruto Movie 3: Dai Koufun! Mikazuki Jima no A...\n",
       "1905                                   Akakichi no Eleven\n",
       "1984                           Naruto: Shippuuden Movie 1\n",
       "2881                  Naruto: Shippuuden Movie 2 - Kizuna\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assume 'anime_id' is 21\n",
    "anime_id = 10\n",
    "\n",
    "# Extract learned embeddings from the model\n",
    "anime_embedding = model.get_layer('anime_embedding').get_weights()[0]\n",
    "target_anime_embedding = anime_embedding[anime_id]\n",
    "\n",
    "# Compute similarity scores between this anime and all others\n",
    "similarities = cosine_similarity([target_anime_embedding], anime_embedding)\n",
    "\n",
    "# Get top 10 most similar animes\n",
    "top_10_indices = similarities[0].argsort()[-10:][::-1]\n",
    "top_10_anime_ids = anime_ids[top_10_indices]\n",
    "\n",
    "# Map encoded IDs back to dataset\n",
    "a = filtered_user[filtered_user.anime_id_encoded.isin(top_10_anime_ids)][['anime_id']]\n",
    "rec_anime = a.anime_id.unique()\n",
    "data[data.mal_id.isin(rec_anime)]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7f7c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4640149"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save processed user ratings to SQLite and CSV\n",
    "filtered_user.to_sql(\"users\", conn, if_exists=\"replace\", index=False)\n",
    "filtered_user.to_csv(\"../data/cleaned_user_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a1ccfd",
   "metadata": {},
   "source": [
    "HYBRID RECOMMENDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "52d7796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_anime_recommendations(user_id,anime_id,model,similarity_matrix,filtered_user,data):\n",
    "    \"\"\"\n",
    "    Hybrid recommendation system combining collaborative filtering (matrix factorization)\n",
    "    and content-based similarity.\n",
    "\n",
    "    Parameters:\n",
    "    - user_id (int): Encoded user ID\n",
    "    - anime_id (int): Encoded anime ID\n",
    "    - model (keras.Model): Trained MF model\n",
    "    - similarity_matrix (np.array): Content-based similarity matrix\n",
    "    - filtered_user (pd.DataFrame): User ratings dataset\n",
    "    - data (pd.DataFrame): Anime dataset\n",
    "    - top_n (int): Number of recommendations to return\n",
    "\n",
    "    Returns:\n",
    "    - List of recommended anime titles\n",
    "    \"\"\"\n",
    "    # Predict user-anime ratings\n",
    "    anime_ids = np.array(list(set(filtered_user.anime_id_encoded)))\n",
    "    anime_size = anime_ids.shape[0]\n",
    "\n",
    "    user_ids = np.array([user_id]*anime_size)\n",
    "    predictions = model.predict([user_ids,anime_ids]) \n",
    "    p = predictions.flatten()\n",
    "\n",
    "    # Get content-based similarity for target anime\n",
    "    s = similarity_matrix[anime_id]\n",
    "\n",
    "    # Hybrid score = weighted average of CB + CF\n",
    "    ratings = 0.5*s + 0.5*p\n",
    "\n",
    "    # Get top-N recommendations \n",
    "    top_anime_index = ratings.argsort()[-30:][::-1]\n",
    "    \n",
    "    # Exclude already watched animes\n",
    "    watched_anime = filtered_user[filtered_user.user_id_encoded == user_id]['anime_id_encoded']\n",
    "    mask = np.isin(top_anime_index, watched_anime)\n",
    "    top_unwatched_anime_index = top_anime_index[~mask]\n",
    "    \n",
    "    # Collect recommended titles\n",
    "    recommended_animes = []\n",
    "    for i in top_unwatched_anime_index:\n",
    "        anime_data = data.iloc[i]\n",
    "        recommended_animes.append(anime_data['title'])\n",
    "        \n",
    "    return recommended_animes\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9fda85f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hybrid recommendations:\n",
      "269/269 [==============================] - 0s 779us/step\n",
      "['Akane Maniax', 'School Days: Valentine Days', 'Pia Carrot e Youkoso!! 2 DX', 'To Heart 2 Adnext', 'Kud Wafter', 'Shingeki no Kyojin: Kuinaki Sentaku', 'Tenchi Muyou! Ryououki: Omatsuri Zenjitsu no Yoru!', 'Hoshi no Koe', 'Tteotda Keunyeo!!', 'Yahari Ore no Seishun Love Comedy wa Machigatteiru. Zoku OVA', 'Tengen Toppa Gurren Lagann Movie Zenyasai: Viral no Amai Yume', 'School Rumble: Ichi Gakki Hoshuu', 'Tokyo Marble Chocolate', 'Clannad: After Story', 'Kidou Senshi Gundam: Dai 08 MS Shoutai', 'Ginga Ojousama Densetsu Yuna: Shinen no Fairy', 'Ranma ½: Yomigaeru Kioku', 'Mahoutsukai Tai!', 'Nekopara OVA', 'Toradora! Recap', 'Chou Hatsumei Boy Kanipan', 'Comic Party Revolution OVA', 'Angel Densetsu', 'Top wo Nerae 2! Diebuster', 'Steins;Gate: Oukoubakko no Poriomania', 'Lime-iro Senkitan: Nankoku Yume Roman', 'Shinpi no Sekai El-Hazard', 'Papa no Iukoto wo Kikinasai! OVA', 'Sweat Punch', 'Kimi ga Nozomu Eien']\n"
     ]
    }
   ],
   "source": [
    "# Example hybrid recommendation\n",
    "print(\"\\nHybrid recommendations:\")\n",
    "print(user_anime_recommendations(60, 243, model, similarity_matrix, filtered_user, data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1548f71",
   "metadata": {},
   "source": [
    "# Notebook Complete\n",
    "\n",
    "This notebook builds a **Hybrid Anime Recommendation System** combining:\n",
    "- Content-based filtering (TF-IDF + PCA + cosine similarity)\n",
    "- Collaborative filtering (Matrix Factorization with embeddings in Keras)\n",
    "- Hybrid approach blending both methods\n",
    "\n",
    "Outputs:\n",
    "- Cleaned datasets saved to SQLite/CSV\n",
    "- Trained recommendation model saved as `.keras`\n",
    "- Similarity matrix saved as `.pkl`\n",
    "\n",
    "Use the `user_anime_recommendations()` function for hybrid recommendations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5950a81c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
